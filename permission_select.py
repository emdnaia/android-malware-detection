import numpy as np
import random
import joblib
import csv
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import LinearSVC
import json
import numpy as np
from util import list_type_files, read_from_file, save_counter_to_csv, concatnp_vertical, shuffle,split_matrix_by_rate
from collections import Counter
from sklearn.metrics import accuracy_score, confusion_matrix 
import sys, os


__MYDIR = os.path.dirname(__file__)

predict_model_path = os.path.join(__MYDIR, 'permission_model.pkl')
explain_model_path = os.path.join(__MYDIR, 'permisson_model.pkl.svc')

def read_content(file_path):
    with open(file_path, 'r') as file:
        str = file.readline()
        return json.loads(str)

def read_all_data(folder, malware):
    all_files = list_type_files(folder, 'json')
    all_files = [file for file in all_files if file.endswith('permission.json')]
    data = []
    for file_path in all_files:
            content = read_content(file_path)
            if not content:
                continue
            if malware == 1:
                data.append(content)
            else:
                if not 'SMS' in json.dumps(content):
                    data.append(content)
    return data

# Step 3: One-hot encode the strings in each item
def one_hot_encode(data, all_permissions):
    # Step 3: Create the one-hot encoded representation for each data point
    one_hot_encoded_data = []
    for sublist in data:
        encoded_sublist = one_hot_permissions(sublist, all_permissions)
        one_hot_encoded_data.append(encoded_sublist)
    return one_hot_encoded_data

def one_hot_permissions(permissions, all_permissions):
    element_to_index = {element: index for index, element in enumerate(all_permissions)}
    encoded_sublist = [0] * len(element_to_index.keys())
    sublist = list(set(permissions))
    for element in sublist:
        if element in element_to_index:
            index = element_to_index[element]
            encoded_sublist[index] = 1
    return encoded_sublist

def read_all_permission():
    p = os.path.join(__MYDIR, 'permission.txt')
    with open(p, 'r') as f:
        lines = f.readlines()
        lines = [line.strip() for line in lines]
        return lines


def train(X, y):
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    print(X_train.shape)
    print(X_test.shape)

    model_svc = LinearSVC()
    model = RandomForestClassifier()
    model.fit(X_train, y_train)
    model_svc.fit(X_train, y_train)
    joblib.dump(model, predict_model_path)
    joblib.dump(model_svc, explain_model_path)

    y_pred = model.predict(X_test)

    # Evaluate the model's performance
    accuracy = accuracy_score(y_test, y_pred)
    print(f"Accuracy: {accuracy}")
    cm = confusion_matrix(y_test, y_pred)
    TP = cm[1, 1]
    FP = cm[0, 1]
    TN = cm[0, 0]
    FN = cm[1, 0]
    print("TP: ", TP, "FP: ", FP, "TN: ", TN, "FN: ", FN)
    precision = TP / (TP + FP)
    recall = TP / (TP + FN)
    FPR = FP / (FP + TN)
    print("Precision: ", precision, "Recall: ", recall, "FPR: ", FPR)

def stats_for_folder(folder_path, stats_save_path, malware):
    bengin_data = read_all_data(folder_path, malware)
    print("bengin_data: ", len(bengin_data))
    bengin_data_count = len(bengin_data)

    flattened_list = [item for sublist in bengin_data for item in sublist]
    bengin_data_counter = Counter(flattened_list)
    save_counter_to_csv(bengin_data_counter, stats_save_path)
    return bengin_data_count, bengin_data_counter 


def encode_data_from_path(data_path, permissions, bengin):
    bengin_data = read_all_data(data_path, bengin)
    bengin_data = np.array(one_hot_encode(bengin_data, permissions))
    return bengin_data

def generate_accessiblity_data(malware_path):
    malware_data = read_all_data(malware_path, 1)

    def regenerate_data(data):
        return [item for item in data if not 'SMS' in data] + ['android.permission.BIND_ACCESSIBILITY_SERVICE']

    random_selection = random.choices(malware_data, k=3000)
    datas = [regenerate_data(data) for data in random_selection]
    return datas

def get_train_data():
    all_permissions = read_all_permission()
    bengin_path = './train_data/apk/pp助手apk/'
    bengin_data1 = encode_data_from_path(bengin_path, all_permissions, 0)

    bengin_path = './train_data/apk/ApkPure'
    bengin_data2 = encode_data_from_path(bengin_path, all_permissions, 0)

    bengin_data2, _ = shuffle(bengin_data2, np.array([0]*bengin_data2.shape[0]))
    bengin_data2, bengin_test_data = split_matrix_by_rate(bengin_data2, 0.4)

    bengin_data = concatnp_vertical(bengin_data1, bengin_data2)

    malware_path = './train_data/vx_apk/Virusshare.Android_APK_2022/'
    malware_data = encode_data_from_path(malware_path, all_permissions, 1)

    # generete data
    accessiblity_data = generate_accessiblity_data(malware_path)
    permissions = read_all_permission()
    accessiblity_data = np.array(one_hot_encode(accessiblity_data, permissions))

    malware_data = concatnp_vertical(malware_data, accessiblity_data)
    malware_data, _ = shuffle(malware_data, np.array([1]*malware_data.shape[0]))
    malware_data, malware_test_data = split_matrix_by_rate(malware_data, 0.45)
    return bengin_data, malware_data

def evaluate_datasets(model_path, X_test, y_test):
    # Make predictions on the test set
    print('X_test shape: ', X_test.shape)
    model = joblib.load(model_path)
    y_pred = model.predict(X_test)
    print(y_pred.shape)

    accuracy = accuracy_score(y_test, y_pred)
    print(f"Accuracy: {accuracy}")

def evaluate_datasets_and_explain(model, X_text):
    y_pred = model.decision_function(X_text)
    y_pred2 = model.predict(X_text)

    train_data = X_text[0]
    all_permissions = read_all_permission()

    coef = model.coef_[0]
    feature_ranking = np.argsort(abs(coef))[::-1]
    for index in feature_ranking[:10]:
        # if train_data[index] == 1:
        print(index, y_pred[0], y_pred2[0], coef[index], all_permissions[index])
    # print(feature_ranking)


def analysis_model():
    model_path = 'permisson_model.pkl.svc'
    model = joblib.load(model_path)
    coef = model.coef_[0]
    print(' feature len: ',len(coef))
    feature_ranking = np.argsort(coef)[::-1]

    all_permissions = read_all_permission()
    print('all permission len: ', len(all_permissions))

    for i in range(len(coef)):
        print(all_permissions[feature_ranking[i]])


def train_and_evaluate_datasets():
    bengin_train_data, malware_train_data = get_train_data()

    bengin_data, _ = shuffle(bengin_train_data, np.array([1]*bengin_train_data.shape[0]))
    bengin_train_data, bengin_test_data = split_matrix_by_rate(bengin_data, 0.8)

    X_train = np.vstack((bengin_train_data, malware_train_data))
    y_train = [0] * bengin_train_data.shape[0] + [1] * malware_train_data.shape[0]
    train(X_train, y_train)

    print('bengin_test_data: ', bengin_test_data.shape)
    evaluate_datasets(predict_model_path, bengin_test_data, [0]*bengin_test_data.shape[0])

    all_permissions = read_all_permission()
    malware_path = "./train_data/apk/mb/"
    malware_data = encode_data_from_path(malware_path, all_permissions, 1)
    evaluate_datasets(predict_model_path, malware_data, [1]*malware_data.shape[0])


    malware_path = './train_data/vx_apk/2020'
    malware_data = encode_data_from_path(malware_path, all_permissions, 1)
    evaluate_datasets(predict_model_path, malware_data, [1]*malware_data.shape[0])

    malware_path = './train_data/vx_apk/2021'
    malware_data = encode_data_from_path(malware_path, all_permissions, 1)
    evaluate_datasets(predict_model_path, malware_data, [1]*malware_data.shape[0])


def predict(permissions, all_permissions, predict_model):
    print('loaded model: ', predict_model)
    X = one_hot_permissions(permissions, all_permissions)
    y_predict = predict_model.predict([X])
    probs = predict_model.predict_proba([X])
    return y_predict[0], probs[:, 1]

def explain(permissions, all_permissions, explain_model):
    X = one_hot_permissions(permissions, all_permissions)

    coef = explain_model.coef_[0]
    feature_ranking = np.argsort(coef)[::-1]
    results = []
    for index in feature_ranking:
        if X[index] == 1:
            results.append(index)
    results = results[:5] if len(results) > 5 else results

    permissions = []
    
    for result in results:
        permission = all_permissions[result]
        permissions.append(permission)
    return permissions

def test_prob():
    print('test ojb')
    permission_path1 = './test-data/1/permission.json'
    permissions1 = read_content(permission_path1)
    permission_path2 = './test-data/2/permission.json'
    permissions2 = read_content(permission_path2)

    permission_path3 = './test-data/3/permission.json'
    permissions3 = read_content(permission_path3)
    permission_path4 = './test-data/4/permission.json'
    permissions4 = read_content(permission_path4)
    permission_path5 = './test-data/5/permission.json'
    permissions5 = read_content(permission_path5)
    permission_path6 = './test-data/6/permission.json'
    permissions6 = read_content(permission_path6)

    model_path = 'permission_model.pkl'
    all_permissions = read_all_permission()
    X1 = one_hot_permissions(permissions1, all_permissions)
    X2 = one_hot_permissions(permissions2, all_permissions)
    X3 = one_hot_permissions(permissions3, all_permissions)
    X4 = one_hot_permissions(permissions4, all_permissions)
    X5 = one_hot_permissions(permissions5, all_permissions)
    X6 = one_hot_permissions(permissions6, all_permissions)

    model = joblib.load(model_path)
    prob = model.predict_proba([X1, X2, X3, X4, X5, X6])
    print(prob[:,1])


def cmd_predict(argv):
    rs = {}
    try:
        argv = sys.argv
        if len(argv) <= 1:
            raise Exception('argv: permission list')

        all_permissions = read_all_permission()
        permissions = argv[2:]
        print('got permissions: ', permissions)

        # predict
        predict_result, prob = predict(permissions, all_permissions, joblib.load(predict_model_path))
        print('the predict result and prob: ', prob)
        rs = {
            'status': True,
        }

        data = {
            'result': 1 if predict_result > 0 else 0,
        }

        cn = read_from_file(os.path.join(__MYDIR, 'permission_explain_cn.json'))
        en = read_from_file(os.path.join(__MYDIR, 'permission_explain_en.json'))
        if predict_result == 1:
            ps = explain(permissions, all_permissions, joblib.load(explain_model_path))

            tmp_permissions = []
            tmp_permissions_cn = []
            tmp_permissions_en = []
            for p in ps:
                tmp_permissions.append(p)

                tmp_permissions_cn.append(cn[p] if p in cn else None)
                tmp_permissions_en.append(en[p] if p in en else None)

            data['permissions'] = tmp_permissions
            data['permissions_en'] = tmp_permissions_en
            data['permissions_cn'] = tmp_permissions_cn

        rs['data'] = data
    except Exception as e:
        rs = {
            'status': False,
            'error_msg': repr(e),
        }

    finally:
        print('@malware-result: ' + json.dumps(rs))

def cmd_train():
    train_and_evaluate_datasets()

if __name__ == "__main__":
    argv = sys.argv

    if argv[1] == 'predict':
        cmd_predict(argv)
    elif argv[1] == 'train':
        cmd_train()
